# For basic testing, it should run on any hardware
tinyllama:1.1b

# Ministral - vision model with 256K context
ministral-3:3b
# ministral-3-8b

# Embedding model
nomic-embed-text

# Other models
# mistral:instruct
# devstral:24b
# gemma3:4b
# llama2:7b
# llama3.2:3b
# gpt-oss:20b
# deepseek-r1:1.5b
# deepscaler:1.5b
# deepseek-r1:7b
# qwen2.5:0.5b-instruct
# qwen3-vl:2b